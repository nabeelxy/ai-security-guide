# Deepfake and Disinformation Detection

| Date | Title | Venue | Materials | Tags | Short Summary | Summary |
| --- | --- | --- | --- | --- | --- | --- |
| Sep 2024 | From Deception to Detection: The Dual Roles of Large Language Models in Fake News | arXiv | [Paper](https://arxiv.org/pdf/2409.17416) | Fake News, Disinformation, LLM, AI-generated content | Two questions: Can LLMs generate fake news? Can LLM be used to detect fake news? They found that models like C4AI, Zephyr-orpo and Mistral showed no hesistant of generating fake news. However, models like GPT-4, Gemma-1.1 and Phi-3 were hesitant to or didn't generate fake news due to extensive safety protocols in place. In terms of detection capabilities, Llama-3 and Zephyr-orpo demonstrated superior performance in detecting human generated fake news, whereas GPT-4 and Gemma-1.1 showed better detection performance in detecting LLM generated fake news. | |
| Apr 2024 | An analysis of recent advances in deepfake image detection in an evolving threat landscape | IEEE S&P | [Paper](https://arxiv.org/pdf/2404.16212) | deepfake image, foundation models, generative models, deepfake detection | They show how 8 state-of-the-art image deepfake detectors fall short due to two reasons: 1. The emergence of lightweight methods to costomize large generative models enables attackers to create many customized generators and existing defenses do not generlize to these customized ones. 2. The emergence of vision foundation models that are adopted for downstream tasks evading existing defenses. They also propose a content agnostic approach to detect deepfakes. Further, a simple adversarial attack without adding any adversarial noise through careful semantic manipulation of the image content. | |
