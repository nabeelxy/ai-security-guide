# Adversarial Machine Learning

| Date | ID | Title | Venue | Material | Tags | Short Summary | Summary |
|---|---|---|---|---|---|---|---|
| Oct 2024 | Beowulf | Beowulf: Mitigating Model Extraction Attacks Via Reshaping Decision Regions | CCS | | model extraction| |[Link](https://github.com/nabeelxy/ai-security-guide/tree/main/security_for_ai/adversarial_machine_learning/summaries/202410_aml_ccs_beowulf_summary.txt) |
| Sep 2024 | Robust LLMs | Assessing Adversarial Robustness of Large Language Models: An Empirical Study | arXiv | [Paper](https://arxiv.org/pdf/2405.02764) | robustness, survey | | |
| Aug 2024 | SecurityNet | SecurityNet: Assessing Machine Learning Vulnerabilities on Public Models | Usenix | [Paper](https://www.usenix.org/system/files/sec24summer-prepub-617-zhang-boyang.pdf) | stealing, membership inference, backdoor | | |
