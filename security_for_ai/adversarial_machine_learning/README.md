# Adversarial Machine Learning
This section covers adversarial attacks and defenses on machine learning models. While prompt injections fall under AML, due to its prevlance and extensive research, they warrent a sepeate section. Please refer to [LLM Security](https://github.com/nabeelxy/ai-security-guide/tree/main/security_for_ai/llm_security) for more details on prompt injections.

## Recent Publications
| Date |  Title | Venue | Material | Tags | Code | Summary |
|---|---|---|---|---|---|---|
| Aug 2025 | Revisiting Training-Inference Trigger Intensity in Backdoor Attacks | Usenix Security 2025 | [Paper](https://www.usenix.org/system/files/conference/usenixsecurity25/sec25cycle1-prepub-389-lin-chenhao.pdf) | training inference trigger, backdoor attacks | | |
| Feb 2025 |  Adversarial ML Problems Are Getting Harder to Solve and to Evaluate | arXiv | [Paper](https://arxiv.org/pdf/2502.02260) | llm, adversarial ml progress, position paper | | |
| Feb 2025 | Reformulation is All You Need: Addressing Malicious Text Features in DNNs | arXiv | [Paper](https://arxiv.org/pdf/2502.00652) | advesarial manipulation of text, reorientation | | |
| Oct 2024 | Beowulf: Mitigating Model Extraction Attacks Via Reshaping Decision Regions | CCS | | model extraction| |[Link](https://github.com/nabeelxy/ai-security-guide/tree/main/security_for_ai/adversarial_machine_learning/summaries/202410_aml_ccs_beowulf_summary.txt) |
| Sep 2024 |  Assessing Adversarial Robustness of Large Language Models: An Empirical Study | arXiv | [Paper](https://arxiv.org/pdf/2405.02764) | robustness, survey | | |
| Aug 2024 |  A Wolf in Sheep's Clothing: Practical Black-box Adversarial Attacks for Evading Learning-based Windows Malware Detection in the Wild | Usenix Security | [Paper](https://www.usenix.org/system/files/usenixsecurity24-ling.pdf) [Slides](https://www.usenix.org/system/files/usenixsecurity24_slides-ling.pdf) [Talk](https://youtu.be/hmMD1cr3WBo) | malware, windows, aml | | |
| Aug 2024 |  SecurityNet: Assessing Machine Learning Vulnerabilities on Public Models | Usenix | [Paper](https://www.usenix.org/system/files/sec24summer-prepub-617-zhang-boyang.pdf) [Slides](https://www.usenix.org/system/files/usenixsecurity24_slides-zhang-boyang.pdf) [Talk](https://youtu.be/tQvCGHO8cvM) [GitHub](https://trustairlab.github.io/SecurityNet/)| stealing, membership inference, backdoor | | |
