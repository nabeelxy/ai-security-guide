# Adversarial Machine Learning

| Date | ID | Title | Venue | Material | Tags | Short Summary | Summary |
|---|---|---|---|---|---|---|---|
| Oct 2024 | Beowulf | Beowulf: Mitigating Model Extraction Attacks Via Reshaping Decision Regions | CCS | | model extraction| |[Link](https://github.com/nabeelxy/ai-security-guide/tree/main/security_for_ai/adversarial_machine_learning/summaries/202410_aml_ccs_beowulf_summary.txt) |
| Sep 2024 | Robust LLMs | Assessing Adversarial Robustness of Large Language Models: An Empirical Study | arXiv | [Paper](https://arxiv.org/pdf/2405.02764) | robustness, survey | | |
| Aug 2024 | Blackbox-Malware | A Wolf in Sheep's Clothing: Practical Black-box Adversarial Attacks for Evading Learning-based Windows Malware Detection in the Wild | Usenix Security | [Paper](https://www.usenix.org/system/files/usenixsecurity24-ling.pdf) [Slides](https://www.usenix.org/system/files/usenixsecurity24_slides-ling.pdf) [Talk](https://youtu.be/hmMD1cr3WBo) | malware, windows, aml | | |
| Aug 2024 | SecurityNet | SecurityNet: Assessing Machine Learning Vulnerabilities on Public Models | Usenix | [Paper](https://www.usenix.org/system/files/sec24summer-prepub-617-zhang-boyang.pdf) [Slides](https://www.usenix.org/system/files/usenixsecurity24_slides-zhang-boyang.pdf) [Talk](https://youtu.be/tQvCGHO8cvM) [GitHub](https://trustairlab.github.io/SecurityNet/)| stealing, membership inference, backdoor | | |
