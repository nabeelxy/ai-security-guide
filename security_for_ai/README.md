# Security for AI
In this section, we explore various security threats and defenses to AI models including traditional ML, DL and GenAI (LLMs).

Specifically, we keep a close eye on the following areas:
* [LLM Security](https://github.com/nabeelxy/ai-security-guide/tree/main/security_for_ai/llm_security)
* [Adversarial Machine Learning](https://github.com/nabeelxy/ai-security-guide/tree/main/security_for_ai/adversarial_machine_learning)
* Explainability
* Safety, Bias and Fairness
* RAG Security
* Agents Security
* ML Security
* Model Supply Chain Security
* Benchmarks

We also track the security startups that defend AI.
