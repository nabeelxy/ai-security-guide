# Prompt Injection

## Recent publications on LLM security and privacy

| Date | Title | Venue | Material | Tags | Code | Summary | 
| --- |  --- | --- | --- | --- | --- | --- |
| Nov 2025 |  BrowseSafe: Understanding and Preventing Prompt Injection Within AI Browser Agents | Purdue, Perplexity | [Paper](https://arxiv.org/pdf/2511.20597) [NotebookLM](https://notebooklm.google.com/notebook/5781271e-1c76-483b-8966-99b6c491d2a4)| indirection prompt injection, web, agents, benchmark | [Model](https://huggingface.co/perplexity-ai/browsesafe) | [Review](reviews/browsesafe.md)|
| Oct 2025 |  WAInjectBench: Benchmarking Prompt Injection Detections for Web Agents | Duke | [Paper](https://arxiv.org/pdf/2510.01354) [NotebookLM](https://notebooklm.google.com/notebook/6267b5c9-950f-4a8f-9bb8-51c3906b468a)| web agents, benchmark | [Github](https://github.com/Norrrrrrr-lyn/WAInjectBench) | [Review](reviews/wa_inject_bench.md) |
| Oct 2025 |  THE ATTACKER MOVES SECOND: STRONGER ADAPTIVE ATTACKS BYPASS DEFENSES AGAINST LLM JAILBREAKS AND PROMPT INJECTIONS | arXiv, OpenAI, Anthropic, Google | [Paper](https://arxiv.org/pdf/2510.09023) | robustenss, adaptive-attacks | | |
| Jul 2025 |  Meta SecAlign: A Secure Foundation LLM Against Prompt Injection Attacks | Meta, Berkeley | [Paper](https://arxiv.org/pdf/2507.02735) | prompt injection, alignment | | |
| Jun 2025 | LLMail-Inject: A Dataset from a Realistic Adaptive Prompt Injection Challenge | Microsoft | [Paper](https://arxiv.org/pdf/2506.09956v1) | prompt injection, emails, agents | [Huggingface](https://huggingface.co/datasets/microsoft/llmail-inject-challenge) | |
| Jun 2025 | Design Patterns for Securing LLM Agents against Prompt Injections | arXiv  | [Paper](https://arxiv.org/pdf/2506.08837) | prompt injection, design patterns | | |
| Apr 2025 | WASP: Benchmarking Web Agent Security Against Prompt Injection Attacks | Meta | [Paper](https://arxiv.org/pdf/2504.18575) | benchmark, web security agents | | |
| Mar 2025 |  Defeat Prompt Injections by Design | arXiv | [Paper](https://arxiv.org/pdf/2503.18813) | prompt injection, defense, agents, AgentDojo | | |
| Jan 2025 |  Benchmarking and Defending Against Indirect Prompt Injection Attacks on Large Language Models | arXiv | [Paper](https://arxiv.org/pdf/2312.14197) | indirect-prompt-injection, benchmark | [Github](https://github.com/microsoft/BIPIA) | |
| Jan 2025 |  Constitutional Classifiers: Defending against Universal Jailbreaks across Thousands of Hours of Red Teaming | arXiv | [Paper](https://arxiv.org/pdf/2501.18837), [Relase Note](https://www.anthropic.com/research/constitutional-classifiers) | aml, robust, universal jailbreak | | |
| Nov 2024 | AgentDojo: A Dynamic Environment to Evaluate Prompt Injection Attacks and Defenses for LLM Agents | NuerIPS | [paper](https://arxiv.org/pdf/2406.13352) | benchmark, agent | | |
| Aug 2024 | INJECAGENT: Benchmarking Indirect Prompt Injections in Tool-Integrated Large Language Model Agents| arXiv | [paper](https://arxiv.org/pdf/2403.02691) | indirect prompt injection, benchmark | | |
| Aug 2024 |  Formalizing and Benchmarking Prompt Injection Attacks and Defenses | Usenix Security 2025 | [paper](https://www.usenix.org/system/files/usenixsecurity24-liu-yupei.pdf) | prompt injection, attack, defense, LLM-integrated app | [Github](https://github.com/liu00222/Open-Prompt-Injection) | |
| Mar 2024 |  Prompt Inject Attack Against LLM-Integrated Applications | arXiv | [paper](https://arxiv.org/pdf/2306.05499) | Prompt Injection, LLM-Integrated Apps |  | [Review](reviews/pi_llm_apps.md)|
| Mar 2024 |  Defending Against Indirect Prompt Injection Attacks With Spotlighting | Microsoft | [paper](https://arxiv.org/pdf/2403.14720) | indirect prompt injection, prompt engineering | | |
| Dec 2023 | Benchmarking and Defending Against Indirect Prompt Injection Attacks on Large Language Models | KDD 2025 | [Paper](https://arxiv.org/pdf/2312.14197) [GitHub](https://github.com/microsoft/BIPIA)| indirect prompt injection, attack, defense | | |
| May 2023 | Not what you’ve signed up for: Compromising Real-World LLM-Integrated Applications with Indirect Prompt Injection | arXiv | [Paper](https://arxiv.org/pdf/2302.12173) [NotebookLM](https://notebooklm.google.com/notebook/1cfef5c4-f772-4eb2-a7ca-981dc7c0ad0c)| indirect-prompt-injection | | [Review](reviews/indirect_pi_2023.md)|

## Blogs
* [01-14-2026] [Blog](https://www.varonis.com/blog/reprompt) Reprompt: The Single-Click Microsoft Copilot Attack that Silently Steals Your Personal Data by Veronis. #prompt-injection #api #copilot #chatbot #fetch
* [12-21-2025] [Blog](https://www.lasso.security/blog/red-teaming-browsesafe-perplexity-prompt-injections-risks) Red Teaming BrowseSafe: Prompt Injection Risks in Perplexity’s Open-Source Model by Lasso. #BrowseSafe #model #redteaming
* [12-16-2025] [Blog](https://checkmarx.com/zero-post/turning-ai-safeguards-into-weapons-with-hitl-dialog-forging/) Turning AI Safeguards Into Weapons with HITL Dialog Forging by CheckMarx. #prompt-injection #lies-in-the-loop
* [12-08-2025] [Blog](https://noma.security/blog/geminijack-google-gemini-zero-click-vulnerability/) GeminiJack: The Google Gemini Zero-Click Vulnerability Leaked Gmail, Calendar and Docs Data by Noma Security. #GeminiJack
* [12-05-2025] [Blog](https://unit42.paloaltonetworks.com/model-context-protocol-attack-vectors/) New Prompt Injection Attack Vectors Through MCP Sampling by Palo Alto Networks. #prompt-injection #mcp
* [10-06-2025] [Blog](https://www.radware.com/blog/threat-intelligence/zombieagent/) ZombieAgent: New ChatGPT Vulnerabilities Let Data Theft Continue (and Spread) by Radware. #chatgpt #connectors
* [10-04-2025] [Blog](https://layerxsecurity.com/blog/cometjacking-how-one-click-can-turn-perplexitys-comet-ai-browser-against-you/) CometJacking: How One Click Can Turn Perplexity’s Comet AI Browser Against You by LayerX. #api #prompt-injection #perplexityai #comet
* [-9-18-2025] [Blog](https://splx.ai/blog/chatgpt-agent-solves-captcha) ChatGPT Agent Violates Policy and Solves Image CAPTCHAs by Zscaler. #prompt-injection #captcha-solving #chatgpt
* [09-18-2025] [Blog](https://www.radware.com/blog/threat-intelligence/shadowleak/) ShadowLeak: A Zero-Click, Service-Side Attack Exfiltrating Sensitive Data Using ChatGPT’s Deep Research Agent by Radware. #chatgpt #deepresearch
* [08-08-2025] [Blog](https://neuraltrust.ai/blog/gpt-5-jailbreak-with-echo-chamber-and-storytelling) GPT-5 Jailbreak with Echo Chamber and Storytelling by NaturalTrust. #echoleak
* [07-15-2025] [Disclosure](https://www.tenable.com/security/research/tra-2025-22) OpenAI ChatGPT Prompt Injection via ?q= Parameter in Web Interface by Tenable. #prompt-injection #api #openai
